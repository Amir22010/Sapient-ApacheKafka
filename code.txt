docker run --rm -it -p 2181:2181 -p 3030:3030 -p 8081:8081 -p 8082:8082 -p 8083:8083 -p 9092:9092 -e ADV_HOST=192.168
.99.100 landoop/fast-data-dev


docker run --rm ches/kafka kafka-topics.sh --create --topic demo-1-standalone --partitions 3 --replication-factor 1 --zookeeper 192.168.99.100:2181

docker run --rm --interactive ches/kafka kafka-console-producer.sh --broker-list  192.168.99.100:9092 --topic demo-1-standalone << EOF
HI
HELLO
KAFKA
EOF

docker run --rm --interactive ches/kafka kafka-console-consumer.sh --bootstrap-server  192.168.99.100:9092 --from-beginning --topic demo-1-standalone




Start Docker Toolbox 

Create Topic 192.168.99.100

Enable Schema

Create influxdb

connect file sources to topic producers ----analyzing and processing  with spark stream api

sink connector influxdb

sink topics data to influxdb

http://www.landoop.com/blog/2016/12/kafka-influxdb/



